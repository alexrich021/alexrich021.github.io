<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Alex Rich</title>
  
  <meta name="author" content="Alex Rich">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Alex Rich</name>
              </p>
              <p>I'm a PhD student in computer science at <a href="https://cs.ucsb.edu/">UCSB</a>, advised by <a href="https://sites.cs.ucsb.edu/~holl">Tobias Höllerer</a>. I am broadly interested in machine learning, computer vision, and computer graphics. My research focuses on multi-view stereo and 3D reconstruction, with applications in augmented and virtual reality, autonomous navigation, and more.
              </p>
              <p>
              I earned a B.S. from <a href="https://www.math.ucsb.edu/">UCSB</a> in mathematics, where I worked with <a href="http://web.math.ucsb.edu/~millett/">Kenneth C. Millett</a> on knot theory and the analysis of common subknots in minimal prime knot presentations.
              </p>
              <p style="text-align:center">
                <a href="mailto:anrich@ucsb.edu">Email</a> &nbsp/&nbsp
                <a href="https://github.com/alexrich021">Github</a>
                <!-- <a href="https://scholar.google.com/citations?hl=en&user=b0tkYB4AAAAJ">Google Scholar</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Alex_Rich.jpg"><img style="width:100%;max-width:100%;border-radius:50%" alt="profile photo" src="images/Alex_Rich.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/3dvnet.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://github.com/alexrich021/3dvnet">
                <papertitle>3DVNet: Multi-View Depth Prediction and Volumetric Refinement</papertitle>
              </a>
              <br>
              <strong>Alexander Rich</strong>,
              <a href="https://noahstier.github.io">Noah Stier</a>,
              <a href="https://web.ece.ucsb.edu/~psen/">Pradeep Sen</a>,
              <a href="https://sites.cs.ucsb.edu/~holl">Tobias Höllerer</a>
              <br>
              <em>3DV</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2112.00202">arXiv</a>
              <p></p>
              <p>We introduce a deep multi-view stereo network that jointly models all depth maps in scene space, allowing it to learn geometric priors across entire scenes. It iteratively refines its predictions, leading to highly coherent reconstructions.</p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/vortx.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://noahstier.github.io/vortx">
                <papertitle> VoRTX: Volumetric 3D Reconstruction with Transformers for Voxel-wise View Selection and Fusion</papertitle>
              </a>
              <br>
              <a href="https://noahstier.github.io">Noah Stier</a>,
              <strong>Alexander Rich</strong>,
              <a href="https://web.ece.ucsb.edu/~psen/">Pradeep Sen</a>,
              <a href="https://sites.cs.ucsb.edu/~holl">Tobias Höllerer</a>
              <br>
              <em>3DV</em>, 2021
              <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://noahstier.github.io/vortx">project page</a>
              /
              <a href="https://arxiv.org/abs/2112.00236">arXiv</a>
              <p></p>
              <p>We introduce a 3D reconstruction model with a novel multi-view fusion method based on transformers. It models occlusion by predicting <em>projective occupancy</em>, which reduces noise and leads to more detailed and complete reconstructions.</p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/ildav_archviz.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://github.com/vivianross06/Synthetic-Data-Generation-ICCV-2021">
                <papertitle>Using Synthetic Data Generation to Probe Multi-View Stereo Networks</papertitle>
              </a>
              <br>
              Pranav Acharya,
              Daniel Lohn,
              Vivian Ross,
              Maya Ha,
              <strong>Alexander Rich</strong>,
              <a href="https://ehsansayyad.com/">Ehsan Sayyad</a>,
              <a href="https://sites.cs.ucsb.edu/~holl">Tobias Höllerer</a>
              <br>
              <em>ILDAV Workshop, Adjunct Proceedings of ICCV</em>, 2021
              <br>
              <a href="https://openaccess.thecvf.com/content/ICCV2021W/ILDAV/papers/Acharya_Using_Synthetic_Data_Generation_To_Probe_Multi-View_Stereo_Networks_ICCVW_2021_paper.pdf">PDF</a>
              <p></p>
              <p>We introduce a synthetic data generation pipeline, which produces image sequences for multi-view stereo methods given 3D scene models as input. We utilize this pipeline to study existing multi-view-stereo depth-prediction methods. Among other results, we find that camera height and vertical camera viewing angle are the parameters that cause the most variation in depth-prediction errors on these image sequences.</p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/augdesc.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://github.com/KentoNishi/Augmentation-for-LNL">
                <papertitle>Augmentation Strategies for Learning with Noisy Labels</papertitle>
              </a>
              <br>
              Kento Nishi,
              <a href="https://sites.cs.ucsb.edu/~yding/">Yi Ding</a>,
              <strong>Alex Rich</strong>,
              <a href="https://sites.cs.ucsb.edu/~holl">Tobias Höllerer</a>
              <br>
              <em>CVPR</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2103.02130">arXiv</a>
              <p></p>
              <p>We propose <em>Augmented Descent</em>, a data augmentation strategy for training deep classifiers robust to incorrect labels in the training set. This technique works by using one set of augmentations for loss modeling tasks common to existing noise-robust training methods, while using a separate set of augmentations for backpropagation.</p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/knot_fingerprint.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://web.math.ucsb.edu/~millett/Papers/2016MillettRich.pdf">
                <papertitle>More Knots in Knots: a study of classical knot diagrams</papertitle>
              </a>
              <br>
              <a href="http://web.math.ucsb.edu/~millett/">Kenneth C. Millett</a>,
              <strong>Alex Rich</strong>
              <br>
              <em>Journal of Knot Theory and its Ramifications</em>, 2017
              <br>
              <a href="http://web.math.ucsb.edu/~millett/Papers/2016MillettRich.pdf">PDF</a>
              <p></p>
              <p>We perform a comprehensive study of subknots in minimal prime knot presentations through 15 crossings. We find among this set of 313,258 prime knot presentations, 99.83% contain a trefoil subknot and every knot contains either a trefoil subknot or a figure-eight subknot.</p>
            </td>
          </tr> 

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Website source code from <a href="https://jonbarron.info/">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
